# First verison of a simple linear regression algorithm in MAMBA, the
# MPC language of the SCALE-MAMBA library
# The algorithm is an adapted verison of the one to be found here:
# https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/

# Author: Florian Apfelbeck, July, 2018

# TODO:
# - Enable external input of sint arrays
# - implement ability to split arrays
# - commment code
# - check if NULL is implemented in a good way / if thats best practice
# - split in seperate files
# - Ensure correct function of code and testing
# (do not use arrays but MemValue)
# - improve multiple additions to same value, e.g., in sum function
# implement multidimenitonal CustVector (to have x and y values in one vector)
# - create README elaborating how to run this with documentation of changes in
# SCALE-MAMBA source code (files IO.h, Player.cpp and new Input_OUtput_* files)
# - consider implementing possibility for external input of sfloats into the
# SCALE-MAMBA library

from Compiler import mpc_math, floatingpoint
from random import seed, randrange

sfloat.vlen = 15 # Length of mantissa in bits
sfloat.plen = 10 # Length of exponent in bits
sfloat.kappa = 4 # Statistical security parameter for floats

NULL = -123456789

MAX_ARRAY_LENGTH = 10000
MAX_ARRAY_LENGTH_NBIT = 14


## Next # TODO:
# 2. Comments
# 3. split files
# 4. test on swedish set


## preliminary implemetation of svector. To be improved ##
# TODO: implement indexing
# TODO: use i instead of self.end_ptr all the time
class CustVector(object):

    def __init__(self):
        self.s_vector = sint.Array(MAX_ARRAY_LENGTH)
        self.end_ptr = MemValue(-1)
        self.s_vector[0] = NULL
        # self.i = MemValue(NULL)

    @method_block
    def pop(self, index=None):
        # TODO: change to if_then()
        if index is None:
            i = self.end_ptr + 0
            self.end_ptr.write(self.end_ptr - 1)
        else:
            i = index

        element = self.s_vector[i]
        self.s_vector[i] = NULL
        return element


    @method_block
    def get_element(self, index):
        # TODO: checge this to use of [] operator
        element =  self.s_vector[index]
        return element

    @method_block
    def set_element(self, index, element):
        # TODO: change this to [] operator
        self.s_vector[index] = element
        # print_ln("element %s at %s changed!", element.reveal(), index)

    @method_block
    def push_back(self, element):
        self.end_ptr.write(self.end_ptr + 1)
        self.s_vector[self.end_ptr] = element
        self.s_vector[self.end_ptr + 1] = NULL

    @method_block
    def back(self):
        if_then(self.end_ptr == -1)
        result = sint(NULL)
        else_then()
        result = self.s_vector[self.end_ptr]
        end_if()
        return result

    @method_block
    def length(self):
        return sint(self.end_ptr + 1)

    # show the first x elements (length) of the vector
    @method_block
    def show(self, length):
        @for_range(length)
        def _(i):
            print_ln("%s", self.s_vector[i].reveal())

## function to read in external private array ##
def get_external_private_array(cust_vector, channel, player):
    open_channel(channel)
    condition = MemValue(cint(1))
    i = MemValue(cint(0))

    @do_while
    def _():
        input = sint.get_private_input_from(player)
        print_ln("input reveal %s", input.reveal())

        if_then(input.reveal() != NULL)
        cust_vector.push_back(input)
        i.write(i + 1)

        else_then()
        condition.write(0)
        end_if()

        return condition > 0

    close_channel(channel)


# #############################
# x_tr = CustVector()
# x_te = CustVector()
# y_tr = CustVector()
# y_te = CustVector()
#
# x_tr.push_back(5)
# x_tr.push_back(20)
# x_tr.push_back(3)
# x_tr.push_back(11)
# x_tr.push_back(6)
# x_tr.push_back(12)
# x_tr.push_back(18)
# x_tr.push_back(13)
# x_tr.push_back(14)
# x_tr.push_back(19)
# x_tr.push_back(10)
# x_tr.push_back(7)
# x_tr.push_back(2)
# x_tr.push_back(9)
#
# x_te.push_back(1)
# x_te.push_back(4)
# x_te.push_back(8)
# x_te.push_back(15)
# x_te.push_back(16)
# x_te.push_back(17)
#
# y_tr.push_back(17)
# y_tr.push_back(4)
# y_tr.push_back(78)
# y_tr.push_back(45)
# y_tr.push_back(64)
# y_tr.push_back(53)
# y_tr.push_back(2)
# y_tr.push_back(42)
# y_tr.push_back(41)
# y_tr.push_back(44)
# y_tr.push_back(9)
# y_tr.push_back(23)
# y_tr.push_back(32)
# y_tr.push_back(14)
#
# y_te.push_back(66)
# y_te.push_back(12)
# y_te.push_back(14)
# y_te.push_back(94)
# y_te.push_back(52)
# y_te.push_back(18)
# #################################


## use this for testing CustVector ##
def test_Custvector(vector):
    get_external_private_array(vector, 1005, 1)
    vector.show(20)
    print_ln("----")
    length = vector.length()
    element = vector.back()
    print_ln("length: %s", length.reveal())
    print_ln("elemnt: %s", element.reveal())
    print_ln("=============")

    vector.show(20)
    print_ln("----")
    length = vector.length()
    element = vector.back()
    print_ln("length: %s", length.reveal())
    print_ln("elemnt: %s", element.reveal())
    print_ln("=============")

## split data set into train and test set ##
def split_up(data, split):
    # initialize x_train and x_test (array length has to be known at compile time,
    # therefore, initialization with taking split into acocunt not possible)
    train = CustVector()
    test = CustVector()
    data_length = data.length()

    # calculate lengths of train and test arrays
    train_target_length = sfloat(data_length) * sfloat(split)
    train_target_length = mpc_math.floor_fx(sfix(train_target_length)) + 1
    test_target_length = data_length - train_target_length

    # cast train_target_length to sint()
    train_target_length_sint = floatingpoint.Trunc(train_target_length.v, train_target_length.k - train_target_length.f, train_target_length.f, train_target_length.kappa)
    A = sint.Array(1)
    A[0] = sint(train_target_length_sint)

    @do_while
    def _():
        index = MemValue(sint.get_random_int(MAX_ARRAY_LENGTH_NBIT))
        condition = MemValue(1)
        count = MemValue(0)
        element = MemValue(cint(NULL))
        # loop until random number within data_length found and no NULL element
        # at that index
        @do_while
        def _():
            # if 1
            if_then(index.reveal() < data_length.reveal())
            # TODO make comparison private
            element.write(data.get_element(index.reveal()).reveal())

            # if 2
            if_then(element != cint(NULL))
            ind = index.reveal()
            data.set_element(ind, NULL)
            condition.write(0)

            # elseif 2
            else_then()
            count.write(count + 1)
            index.write(sint.get_random_int(MAX_ARRAY_LENGTH_NBIT))
            # close if 2
            end_if()

            # elseif 1
            else_then()
            count.write(count + 1)
            index.write(sint.get_random_int(MAX_ARRAY_LENGTH_NBIT))
            # close if 1
            end_if()

            return condition > 0

        train.push_back(element)
        # print_ln("element %s", element)
        # print_ln("index out %s", index.reveal())
        print_ln("train length %s", train.length().reveal())
        print_ln("train traget length %s", A[0].reveal())

        delta_check = A[0].reveal() - train.length().reveal()
        print_ln("delta_check %s", delta_check)

        return delta_check > 0

    # print_ln("------------------------")
    # train.show(20)
    # print_ln("------------------------")
    #
    # print_ln("------------------------")
    # data.show(20)
    # print_ln("------------------------")

    # loop over data vector to assign all left in data to test
    @for_range(data_length.reveal())
    def _(i):
        element = data.get_element(cint(i))
        if_then(element.reveal() != NULL)
        test.push_back(element)
        end_if()

    # print_ln("------------------------")
    # test.show(20)
    # print_ln("------------------------")

    return train, test


### simple linear regression ###
## sum function ##
def sum(vector):
    result_array = sfloat.Array(1)
    result_array[0] = 0.0
    @while_do(lambda a: a < vector.length().reveal(), 0)
    def _(i):
        result_array[0] = result_array[0] + sfloat(vector.get_element(i))
        return i+1
    return result_array[0]

## mean function ##
def mean(vector):
    return sum(vector) / sfloat(vector.length())

## rmse_metric ##
def rmse_metric(actual, predicted_array):
    sum_err = sfloat.Array(1)
    sum_err[0] = 0.0
    rmse = sfloat(0.0)
    actual_length = actual.length().reveal()

    @for_range(actual_length)
    def _(i):
        prediction_err = predicted_array[i] - sfloat(actual.get_element(i))
        print_ln("pred_err %s", prediction_err.reveal())
        sum_err[0] += (prediction_err ** 2)

    print_ln("sum_err %s", sum_err[0].reveal())
    mean_err = sum_err[0] / sfloat(sint(actual_length))
    print_ln("act_len %s", actual_length)
    print_ln("act_len type %s", type(actual_length))
    print_ln("sfloat sint act_len %s", sfloat(sint(actual_length)).reveal())
    print_ln("sfloat act_len %s", sfloat(actual_length).reveal())
    print_ln("mean_err %s", mean_err.reveal())
    rmse = mpc_math.sqrt_simplified_fx(sfix(mean_err))
    return rmse

## covariance ##
def covariance(x_vector, x_mean, y_vector, y_mean):
    covar = sfloat.Array(1)
    covar[0] = 0.0
    @for_range(x_vector.length().reveal())
    def _(i):
        covar[0] = covar[0] + (sfloat(x_vector.get_element(i)) - x_mean) * (sfloat(y_vector.get_element(i)) - y_mean)
    return covar[0]

## variance ##
def variance(vector, mean):
    var = sfloat.Array(1)
    var[0] = 0.0
    @for_range(vector.length().reveal())
    def _(i):
        var[0] = var[0] + (sfloat(vector.get_element(i)) - mean) ** 2
    return var[0]

## coefficients ##
def coefficients(x_vector, y_vector):
    x_mean = mean(x_vector)
    y_mean = mean(y_vector)
    b1 = covariance(x_vector, x_mean, y_vector, y_mean) / variance(x_vector, x_mean)
    b0 = y_mean - b1 * x_mean
    return b0, b1

## slr algorithm ##
def simple_linear_regression(x_train, x_test, y_train):
    x_test_length = x_test.length().reveal()
    predictions = sfloat.Array(MAX_ARRAY_LENGTH)
    b0, b1 = coefficients(x_train, y_train)
    @for_range(x_test_length)
    def _(i):
        predictions[i] = b0 + b1 * sfloat(x_test.get_element(i))
    return predictions

## evaluate ##
def evaluate(x_train, x_test, y_train, y_test):
    predicted = simple_linear_regression(x_train, x_test, y_train)
    rmse = rmse_metric(y_test, predicted)
    # print_ln("pred ty %s", type(predicted))
    return rmse

###########################
x = CustVector()
get_external_private_array(x, 2005, 1)
print_ln("+ this is x ++++++++++++++++++++++")
x.show(20)
print_ln("+++++++++++++++++++++++")

y = CustVector()
get_external_private_array(y, 3005, 1)
print_ln("+ this is y +++++++++++++++++++++")
y.show(20)
print_ln("+++++++++++++++++++++++")

split = 0.7
x_train, x_test = split_up(x, split)
y_train, y_test = split_up(y, split)

print_ln("- x_train -----------------------")
x_train.show(20)
print_ln("------------------------")

print_ln("- x_test -----------------------")
x_test.show(20)
print_ln("------------------------")

print_ln("- y_train -----------------------")
y_train.show(20)
print_ln("------------------------")

print_ln("- y_test -----------------------")
y_test.show(20)
print_ln("------------------------")
# #######################################

#################################################

# x_tr = CustVector()
# x_te = CustVector()
# y_tr = CustVector()
# y_te = CustVector()
#
# @for_range(10)
# def _(i):
#     x_tr.push_back(i)
#     y_tr.push_back(i)
#
# @for_range(3)
# def _(i):
#     x_te.push_back(i)
#     y_te.push_back(i)

# vector = CustVector()
# test_Custvector(vector)
######################
# sum_error 7070.603827319998
# mean error 1178.4339712199996
# RMSE: 34.328

rmse = evaluate(x_train, x_test, y_train, y_test)
# rmse = evaluate(x_tr, x_te, y_tr, y_te)
print_ln("==========================")
print_ln("RMSE: %s", rmse.reveal())
print_ln("==========================")

# # get sqrt rights
# div = sfloat(7025.24) / sfloat(6)
# print_ln("div %s", div.reveal())
#
# mean_err = sfloat(1319.763547282937452819363)
# rmse = mpc_math.sqrt_simplified_fx(sfix(mean_err))
# print_ln("+++++++++++++++++++")
# print_ln("test rmse: %s", rmse.reveal())
# print_ln("+++++++++++++++++++")
